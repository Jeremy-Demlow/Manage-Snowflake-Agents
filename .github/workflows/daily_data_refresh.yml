# Daily Data Refresh Pipeline
# ============================
# Runs at 5am PST (1pm UTC) daily to:
# 1. Generate incremental ski resort data
# 2. Run DBT fact tables
# 3. Refresh semantic views
#
# Uses official Snowflake CLI GitHub Action:
# https://github.com/snowflakedb/snowflake-cli-action

name: Daily Data Refresh

on:
  schedule:
    # 5am PST = 1pm UTC (13:00)
    - cron: '0 13 * * *'

  # Allow manual trigger
  workflow_dispatch:
    inputs:
      days:
        description: 'Number of days to generate'
        required: false
        default: '1'
      full_refresh:
        description: 'Force full DBT refresh'
        required: false
        default: 'false'
        type: boolean

jobs:
  data-refresh:
    name: Generate Data & Run DBT
    runs-on: ubuntu-latest

    # Snowflake credentials (same pattern as deploy.yml)
    env:
      SNOWFLAKE_CONNECTIONS_DEFAULT_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_CONNECTIONS_DEFAULT_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_CONNECTIONS_DEFAULT_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
      SNOWFLAKE_CONNECTIONS_DEFAULT_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      SNOWFLAKE_CONNECTIONS_DEFAULT_DATABASE: SKI_RESORT_DB
      SNOWFLAKE_CONNECTIONS_DEFAULT_SCHEMA: RAW
      SNOWFLAKE_CONNECTIONS_DEFAULT_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}

    steps:
      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      # â”€â”€â”€ Snowflake CLI Setup (Official Action) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: ðŸ”§ Setup Snowflake CLI
        uses: snowflakedb/snowflake-cli-action@v1.5
        with:
          cli-version: "latest"
          default-config-file-path: "config.toml"

      - name: âœ… Test Snowflake Connection
        run: |
          echo "Testing Snowflake connection..."
          snow --version
          snow connection test
          echo "âœ… Connection successful!"

      # â”€â”€â”€ Python Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ðŸ“¦ Install Python Dependencies
        run: |
          pip install --upgrade pip
          pip install "snowflake-snowpark-python[pandas]" pandas pyarrow numpy pyyaml toml pydantic cryptography

      # â”€â”€â”€ Check Data Coverage & Backfill â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: ðŸ” Check Data Coverage
        id: check_coverage
        run: |
          echo "ðŸ“Š Checking existing data coverage..."

          # Get the latest date in the data
          LATEST_DATE=$(snow sql -q "
            SELECT COALESCE(MAX(VISIT_DATE), '2025-12-01')::DATE as latest_date
            FROM SKI_RESORT_DB.RAW.PASS_USAGE
          " --format json 2>/dev/null | python3 -c "import sys,json; data=json.load(sys.stdin); print(data[0]['LATEST_DATE'] if data else '2025-12-01')" || echo "2025-12-01")

          echo "Latest date in data: $LATEST_DATE"

          # Calculate days to backfill (from latest_date+1 to today)
          TODAY=$(date +%Y-%m-%d)
          DAYS_MISSING=$(python3 -c "
          from datetime import datetime, timedelta
          latest = datetime.strptime('$LATEST_DATE', '%Y-%m-%d')
          today = datetime.strptime('$TODAY', '%Y-%m-%d')
          # Generate from the day after latest through today
          days = (today - latest).days
          print(max(days, 1))  # At least 1 day
          ")

          # Calculate start date (day after latest)
          START_DATE=$(python3 -c "
          from datetime import datetime, timedelta
          latest = datetime.strptime('$LATEST_DATE', '%Y-%m-%d')
          start = latest + timedelta(days=1)
          print(start.strftime('%Y-%m-%d'))
          ")

          echo "Today: $TODAY"
          echo "Days to generate: $DAYS_MISSING"
          echo "Start date: $START_DATE"

          # Set outputs for next step
          echo "days_missing=$DAYS_MISSING" >> $GITHUB_OUTPUT
          echo "start_date=$START_DATE" >> $GITHUB_OUTPUT
          echo "latest_date=$LATEST_DATE" >> $GITHUB_OUTPUT

      - name: ðŸ“Š Generate Incremental Data
        working-directory: data_generation
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_DATABASE: SKI_RESORT_DB
          SNOWFLAKE_SCHEMA: RAW
        run: |
          DAYS="${{ github.event.inputs.days || steps.check_coverage.outputs.days_missing }}"
          START_DATE="${{ steps.check_coverage.outputs.start_date }}"

          echo "ðŸŽ¿ Generating $DAYS day(s) of ski resort data starting from $START_DATE..."

          if [ "$DAYS" -gt 0 ]; then
            python generate_daily_increment.py \
              --date "$START_DATE" \
              --days "$DAYS" \
              --connection default
          else
            echo "âœ… Data is up to date, no backfill needed"
          fi

      # â”€â”€â”€ DBT Setup & Run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: ðŸ“¦ Install DBT
        run: pip install dbt-snowflake

      - name: ðŸ”§ Configure DBT Profile
        run: |
          echo "Using project profiles.yml with env vars"
          # The dbt_ski_resort/profiles.yml uses {{ env_var('SNOWFLAKE_PASSWORD') }}

      - name: ðŸ“¦ Install DBT Dependencies
        working-directory: dbt_ski_resort
        env:
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |
          echo "ðŸ“¦ Installing DBT dependencies..."
          dbt deps

      - name: ðŸ—ï¸ Run DBT Fact Tables
        working-directory: dbt_ski_resort
        env:
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |
          echo "ðŸ“ˆ Running DBT fact models..."
          if [ "${{ github.event.inputs.full_refresh }}" = "true" ]; then
            echo "Full refresh requested"
            dbt run --select "marts.facts" --full-refresh
          else
            dbt run --select "marts.facts"
          fi

      - name: ðŸŽ¯ Run DBT Semantic Views
        working-directory: dbt_ski_resort
        env:
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |
          echo "ðŸ”„ Refreshing semantic views..."
          dbt run --select "marts.semantic"

      # â”€â”€â”€ Verification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: âœ… Verify Data Load
        run: |
          echo "ðŸ“‹ Verifying data refresh..."
          snow sql -q "
            SELECT VISIT_DATE, COUNT(*) as visitors
            FROM SKI_RESORT_DB.RAW.PASS_USAGE
            WHERE VISIT_DATE >= DATEADD(day, -7, CURRENT_DATE())
            GROUP BY VISIT_DATE
            ORDER BY VISIT_DATE DESC
            LIMIT 7
          "

      # â”€â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: ðŸ“ Job Summary
        run: |
          echo "## ðŸŽ¿ Daily Data Refresh Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Date:** $(date '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Data Coverage:" >> $GITHUB_STEP_SUMMARY
          echo "- **Previous latest date:** ${{ steps.check_coverage.outputs.latest_date }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Days generated:** ${{ steps.check_coverage.outputs.days_missing }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Start date:** ${{ steps.check_coverage.outputs.start_date }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Steps Completed:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Checked data coverage" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Generated incremental data (backfilled gaps)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Ran DBT fact tables" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Refreshed semantic views" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Verified data load" >> $GITHUB_STEP_SUMMARY
